+++
author = "Rachel Samson"
categories = ["Human-centered AI"]
date = "2019-07-01"
#description = "Human-centered AI"
#featured = "pic03.jpg"
#featuredalt = "Pic 3"
featuredpath = "date"
linktitle = ""
title = "What is human-centered AI?"
type = "post"

+++

## Human-centered AI

Note that this is a draft

Human-centered artificial intelligence is an emerging field generally interested in understanding the impact of AI on society, protecting human rights and ensuring the development and use of AI for the betterment of humanity.

## How did we get there?
AI technologies initially emerged from academic research centers, by scientists interested in using machines to solve mathematical problems and geometrical theorems [1].  Developing “humanoid” robots, beating Garry Kasparov at chess, xyz, were all early goals motivating the early research efforts in AI. As with all research endeavors, AI development was driven by scientific curiosity with the goal of solving problems.
Eventually, computing power and data availability reached a point at which AI tools were not only relevant, but necessary to solve complex data driven problems. That is notably what allowed the data-hungry/computing-heavy deep learning methodologies to gain so much success. With the development of AI technologies, those with access to large amounts of data gained an incredible competitive advantage.
With time, we gave up our privacy at the cost of convenience. This has led the giants of google and Facebook capture our data, profit from this knowledge and sell this information to marketers via targeted adds. All businesses are primarily interested in generating profit for their shareholders, the problem is when human data is collected, who protects the data and who benefits from the technological advances?
Human-centered AI attempts to close the gaps between the development of new technologies and consumers, to protect human rights so that we do not face another Cambridge Analytica scandal https://www.businessinsider.com/facebook-87-million-cambridge-analytica-data-2018-4. It is also, in some ways, interested in returning the favor and using AI — and developing AI tools for the benefit of humans and society.

## Where is human-centered AI headed?
Private/Corporate and academic research centers are emerging, to address the gap between AI technologies and society; particularly government regulations. To name a few, there is the NYU [AI Now Institute](https://ainowinstitute.org/), MIT [Human-centered AI Institute](https://hcai.mit.edu/), Stanford [Human-AI institute](https://hai.stanford.edu/), as well as the Institute of Data & Society https://datasociety.net/about/, CIFAR AI & Society https://www.cifar.ca/ai/ai-society, and Humane AI https://www.humane-ai.eu/. All these institutes have a bit of a different focus, but the goal remains to use AI for the benefit of society.
Additionally, numerous guideline on how AI should be built and used have emerged. The main ones are being summarized at the Berkman Klein Center for Internet & Society at Harvard University https://ai-hr.cyber.harvard.edu/. In their report, the authors map these initiatives onto the following ethical AI principles: human rights, promotion of human values, professional responsibility, human control of technology, fairness and non-discriminations, transparency and explainability, safety and security, accountability and privacy. While detached from the development of novel AI technologies per se, these may serve as a framework for ongoing and future discussion regarding ethical AI.

1.	[History of AI](https://towardsdatascience.com/history-of-ai-484a86fc16ef), 2018.
2.	Berkman Klein Center for [Internet & Society](https://ai-hr.cyber.harvard.edu/) at Harvard University.
